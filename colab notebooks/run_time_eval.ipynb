{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"run_time_eval","provenance":[],"collapsed_sections":[],"mount_file_id":"1V_4kTgHYoDUnt-ow_JTJC6uzkX-qfiH7","authorship_tag":"ABX9TyP/CPY03F3zackLVNiPSJ0O"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"hjBExsiwXMtt","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597818749671,"user_tz":-480,"elapsed":2699,"user":{"displayName":"Haoran Chen","photoUrl":"","userId":"05150236894872546263"}}},"source":["import torch\n","import torch.nn as nn\n","from torch.nn.utils import weight_norm\n","\n","\n","class Chomp1d(nn.Module):\n","    def __init__(self, chomp_size):\n","        super(Chomp1d, self).__init__()\n","        self.chomp_size = chomp_size\n","\n","    def forward(self, x):\n","        return x[:, :, :-self.chomp_size].contiguous()\n","\n","\n","class TemporalBlock(nn.Module):\n","    def __init__(self, n_inputs, n_outputs, kernel_size, stride, dilation, padding, dropout=0.2):\n","        super(TemporalBlock, self).__init__()\n","        self.conv1 = weight_norm(nn.Conv1d(n_inputs, n_outputs, kernel_size,\n","                                           stride=stride, padding=padding, dilation=dilation))\n","        self.chomp1 = Chomp1d(padding)\n","        self.relu1 = nn.ReLU()\n","        self.dropout1 = nn.Dropout(dropout)\n","\n","        self.conv2 = weight_norm(nn.Conv1d(n_outputs, n_outputs, kernel_size,\n","                                           stride=stride, padding=padding, dilation=dilation))\n","        self.chomp2 = Chomp1d(padding)\n","        self.relu2 = nn.ReLU()\n","        self.dropout2 = nn.Dropout(dropout)\n","\n","        self.net = nn.Sequential(self.conv1, self.chomp1, self.relu1, self.dropout1,\n","                                 self.conv2, self.chomp2, self.relu2, self.dropout2)\n","        self.downsample = nn.Conv1d(n_inputs, n_outputs, 1) if n_inputs != n_outputs else None\n","        self.relu = nn.ReLU()\n","        self.init_weights()\n","\n","    def init_weights(self):\n","        self.conv1.weight.data.normal_(0, 0.01)\n","        self.conv2.weight.data.normal_(0, 0.01)\n","        if self.downsample is not None:\n","            self.downsample.weight.data.normal_(0, 0.01)\n","\n","    def forward(self, x):\n","        out = self.net(x)\n","        res = x if self.downsample is None else self.downsample(x)\n","        return self.relu(out + res)\n","\n","\n","class TemporalConvNet(nn.Module):\n","    def __init__(self, num_inputs, num_channels, kernel_size=2, dropout=0.2):\n","        super(TemporalConvNet, self).__init__()\n","        layers = []\n","        num_levels = len(num_channels)\n","        for i in range(num_levels):\n","            dilation_size = 2 ** i\n","            in_channels = num_inputs if i == 0 else num_channels[i-1]\n","            out_channels = num_channels[i]\n","            layers += [TemporalBlock(in_channels, out_channels, kernel_size, stride=1, dilation=dilation_size,\n","                                     padding=(kernel_size-1) * dilation_size, dropout=dropout)]\n","\n","        self.network = nn.Sequential(*layers)\n","\n","    def forward(self, x):\n","        return self.network(x)\n"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"hNF9RPCYYq9H","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597818749674,"user_tz":-480,"elapsed":2694,"user":{"displayName":"Haoran Chen","photoUrl":"","userId":"05150236894872546263"}}},"source":["# -*- coding: utf-8 -*-\n","\"\"\"\n","Created on Mon Jul 27 10:42:50 2020\n","\n","@author: Haoran6\n","\"\"\"\n","\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from tqdm import tqdm\n","\n","class DBS_lstm(nn.Module):\n","\n","    def __init__(self, input_dim, hidden_dim, num_stacks):\n","        super(DBS_lstm, self).__init__()\n","        self.lstm_layer = nn.LSTM(input_dim, hidden_dim, num_stacks).double()\n","        self.hidden2dbs = nn.Linear(hidden_dim, 6890*3, bias=False).double()\n","\n","    def forward(self, pose_beta_seq):\n","        num_frames = pose_beta_seq.shape[0]\n","        lstm_out, _ = self.lstm_layer(pose_beta_seq.view(num_frames, 1, -1))\n","        dbs = self.hidden2dbs(lstm_out).view(num_frames, 6890, 3)\n","        return dbs\n","\n","class DBS_gru(nn.Module):\n","\n","    def __init__(self, input_dim, hidden_dim, num_stacks):\n","        super(DBS_gru, self).__init__()\n","        self.gru_layer = nn.GRU(input_dim, hidden_dim, num_stacks).double()\n","        self.hidden2dbs = nn.Linear(hidden_dim, 6890*3, bias=False).double()\n","\n","    def forward(self, pose_beta_seq):\n","        num_frames = pose_beta_seq.shape[0]\n","        gru_out, _ = self.gru_layer(pose_beta_seq.view(num_frames, 1, -1))\n","        dbs = self.hidden2dbs(gru_out).view(num_frames, 6890, 3)\n","        return dbs\n","\n","class DBS_tcn(nn.Module):\n","    \n","    def __init__(self, input_size, output_size, num_channels, kernel_size=3, dropout=0.1):\n","        super(DBS_tcn, self).__init__()\n","        self.tcn = TemporalConvNet(input_size, num_channels, kernel_size, dropout=dropout).double()\n","        self.hidden2dbs = nn.Linear(num_channels[-1], output_size, bias=False).double()\n","\n","    def forward(self, pose_beta_seq):\n","        \"\"\" Input ought to have dimension (N, C_in, L_in), where L_in is the seq_len \"\"\"\n","        num_frames = pose_beta_seq.shape[0]\n","        tcn_out = self.tcn(pose_beta_seq.transpose(0, 1).view(1,-1,num_frames)).transpose(1, 2).squeeze()\n","        dbs = self.hidden2dbs(tcn_out).view(num_frames, 6890, 3)\n","        return dbs"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"vAze6jFaYvi9","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":227},"executionInfo":{"status":"ok","timestamp":1597819763487,"user_tz":-480,"elapsed":3987,"user":{"displayName":"Haoran Chen","photoUrl":"","userId":"05150236894872546263"}},"outputId":"a096af0b-a6a8-4c27-ba1b-dc32af52f104"},"source":["import numpy as np\n","import pickle\n","import torch\n","from torch.nn import Module\n","import os\n","from time import time\n","\n","class DBSModel(Module):\n","  def __init__(self, device=None, model_path='./body_models/smpl/male/model.pkl',\\\n","               dbs_type='tcn',num_c=[512,768,1024],hd=1024,num_sk=5,dbs_model_path=None):\n","    \n","    super(DBSModel, self).__init__()\n","    with open(model_path, 'rb') as f:\n","      params = pickle.load(f)\n","    self.J_regressor = torch.from_numpy(\n","      np.array(params['J_regressor'].todense())\n","    ).type(torch.float64)\n","    if 'joint_regressor' in params.keys():\n","      self.joint_regressor = torch.from_numpy(\n","        np.array(params['joint_regressor'].T.todense())\n","      ).type(torch.float64)\n","    else:\n","      self.joint_regressor = torch.from_numpy(\n","        np.array(params['J_regressor'].todense())\n","      ).type(torch.float64)\n","    self.weights = torch.from_numpy(params['weights']).type(torch.float64)\n","    self.posedirs = torch.from_numpy(params['posedirs']).type(torch.float64)\n","    self.v_template = torch.from_numpy(params['v_template']).type(torch.float64)\n","    self.shapedirs = torch.from_numpy(params['shapedirs']).type(torch.float64)\n","    self.kintree_table = params['kintree_table']\n","    self.faces = params['f']\n","    self.device = device if device is not None else torch.device('cpu')\n","    for name in ['J_regressor', 'joint_regressor', 'weights', 'posedirs', 'v_template', 'shapedirs']:\n","      _tensor = getattr(self, name)\n","      # print('Tensor {} shape: '.format(name), _tensor.shape)\n","      setattr(self, name, _tensor.to(device))\n","    \n","    if dbs_type == 'lstm':\n","        dbs_layer = DBS_lstm(input_dim=289,hidden_dim=hd,num_stacks=num_sk)\n","    elif dbs_type == 'gru':\n","        dbs_layer = DBS_gru(input_dim=289,hidden_dim=hd,num_stacks=num_sk)\n","    elif dbs_type == 'tcn':\n","        dbs_layer = DBS_tcn(input_size=289, output_size=6890*3, num_channels=num_c)\n","    else:\n","        raise AssertionError('dbs_type is wrong')\n","    \n","    self.dbs_layer = dbs_layer.to(device)\n","    \n","    if dbs_model_path is not None:\n","        self.load_state_dict(torch.load(dbs_model_path))\n","        self.eval()\n","    \n","\n","  @staticmethod\n","  def rodrigues(r):\n","    \"\"\"\n","    Rodrigues' rotation formula that turns axis-angle tensor into rotation\n","    matrix in a batch-ed manner.\n","\n","    Parameter:\n","    ----------\n","    r: Axis-angle rotation tensor of shape [batch_size * angle_num, 1, 3].\n","\n","    Return:\n","    -------\n","    Rotation matrix of shape [batch_size * angle_num, 3, 3].\n","\n","    \"\"\"\n","    eps = r.clone().normal_(std=1e-8)\n","    theta = torch.norm(r + eps, dim=(1, 2), keepdim=True)  # dim cannot be tuple\n","    theta_dim = theta.shape[0]\n","    r_hat = r / theta\n","    cos = torch.cos(theta)\n","    z_stick = torch.zeros(theta_dim, dtype=torch.float64).to(r.device)\n","    m = torch.stack(\n","      (z_stick, -r_hat[:, 0, 2], r_hat[:, 0, 1], r_hat[:, 0, 2], z_stick,\n","       -r_hat[:, 0, 0], -r_hat[:, 0, 1], r_hat[:, 0, 0], z_stick), dim=1)\n","    m = torch.reshape(m, (-1, 3, 3))\n","    i_cube = (torch.eye(3, dtype=torch.float64).unsqueeze(dim=0) \\\n","             + torch.zeros((theta_dim, 3, 3), dtype=torch.float64)).to(r.device)\n","    A = r_hat.permute(0, 2, 1)\n","    dot = torch.matmul(A, r_hat)\n","    R = cos * i_cube + (1 - cos) * dot + torch.sin(theta) * m\n","    return R\n","\n","  @staticmethod\n","  def with_zeros(x):\n","    \"\"\"\n","    Append a [0, 0, 0, 1] tensor to a [3, 4] tensor.\n","\n","    Parameter:\n","    ---------\n","    x: Tensor to be appended.\n","\n","    Return:\n","    ------\n","    Tensor after appending of shape [4,4]\n","\n","    \"\"\"\n","    ones = torch.tensor(\n","      [[[0.0, 0.0, 0.0, 1.0]]], dtype=torch.float64\n","    ).expand(x.shape[0],-1,-1).to(x.device)\n","    ret = torch.cat((x, ones), dim=1)\n","    return ret\n","\n","  @staticmethod\n","  def pack(x):\n","    \"\"\"\n","    Append zero tensors of shape [4, 3] to a batch of [4, 1] shape tensor.\n","\n","    Parameter:\n","    ----------\n","    x: A tensor of shape [batch_size, 4, 1]\n","\n","    Return:\n","    ------\n","    A tensor of shape [batch_size, 4, 4] after appending.\n","\n","    \"\"\"\n","    zeros43 = torch.zeros(\n","      (x.shape[0], x.shape[1], 4, 3), dtype=torch.float64).to(x.device)\n","    ret = torch.cat((zeros43, x), dim=3)\n","    return ret\n","\n","  def write_obj(self, verts, file_name):\n","    with open(file_name, 'w') as fp:\n","      for v in verts:\n","        fp.write('v %f %f %f\\n' % (v[0], v[1], v[2]))\n","\n","      for f in self.faces + 1:\n","        fp.write('f %d %d %d\\n' % (f[0], f[1], f[2]))\n","\n","  def forward(self, betas, pose, trans, simplify=False):\n","    \n","    \"\"\"\n","          Construct a compute graph that takes in parameters and outputs a tensor as\n","          model vertices. Face indices are also returned as a numpy ndarray.\n","          \n","          20190128: Add batch support.\n","\n","          Parameters:\n","          ---------\n","          pose: Also known as 'theta', an [N, 24, 3] tensor indicating child joint rotation\n","          relative to parent joint. For root joint it's global orientation.\n","          Represented in a axis-angle format.\n","\n","          betas: Parameter for model shape. A tensor of shape [N, 10] as coefficients of\n","          PCA components. Only 10 components were released by SMPL author.\n","\n","          trans: Global translation tensor of shape [N, 3].\n","\n","          Return:\n","          ------\n","          A 3-D tensor of [N * 6890 * 3] for vertices,\n","          and the corresponding [N * 19 * 3] joint positions.\n","\n","    \"\"\"\n","    batch_num = betas.shape[0]\n","    id_to_col = {self.kintree_table[1, i]: i\n","                 for i in range(self.kintree_table.shape[1])}\n","    parent = {\n","      i: id_to_col[self.kintree_table[0, i]]\n","      for i in range(1, self.kintree_table.shape[1])\n","    }\n","    v_shaped = torch.tensordot(betas, self.shapedirs, dims=([1], [2])) + self.v_template\n","    J = torch.matmul(self.J_regressor, v_shaped)\n","    R_cube_big = self.rodrigues(pose.view(-1, 1, 3)).reshape(batch_num, -1, 3, 3)\n","\n","    if simplify:\n","      v_posed = v_shaped\n","    else:\n","      R_cube = R_cube_big[:, 1:, :, :]\n","      I_cube = (torch.eye(3, dtype=torch.float64).unsqueeze(dim=0) + \\\n","        torch.zeros((batch_num, R_cube.shape[1], 3, 3), dtype=torch.float64)).to(self.device)\n","      lrotmin = (R_cube - I_cube).reshape(batch_num, -1, 1).squeeze(dim=2)\n","      v_posed = v_shaped + torch.tensordot(lrotmin, self.posedirs, dims=([1], [2]))\n","      # print(lrotmin.shape, self.posedirs.shape)\n","    \n","    R_pose = R_cube.reshape(batch_num, -1, 1).squeeze(dim=2)\n","    pose_beta_seq = torch.cat((R_pose, pose, betas),1)\n","    dbs = self.dbs_layer(pose_beta_seq)\n","    v_posed += dbs\n","    \n","    results = []\n","    results.append(\n","      self.with_zeros(torch.cat((R_cube_big[:, 0], torch.reshape(J[:, 0, :], (-1, 3, 1))), dim=2))\n","    )\n","    for i in range(1, self.kintree_table.shape[1]):\n","      results.append(\n","        torch.matmul(\n","          results[parent[i]],\n","          self.with_zeros(\n","            torch.cat(\n","              (R_cube_big[:, i], torch.reshape(J[:, i, :] - J[:, parent[i], :], (-1, 3, 1))),\n","              dim=2\n","            )\n","          )\n","        )\n","      )\n","    \n","    stacked = torch.stack(results, dim=1)\n","    results = stacked - \\\n","      self.pack(\n","        torch.matmul(\n","          stacked,\n","          torch.reshape(\n","            torch.cat((J, torch.zeros((batch_num, 24, 1), dtype=torch.float64).to(self.device)), dim=2),\n","            (batch_num, 24, 4, 1)\n","          )\n","        )\n","      )\n","    # Restart from here\n","    T = torch.tensordot(results, self.weights, dims=([1], [1])).permute(0, 3, 1, 2)\n","    rest_shape_h = torch.cat(\n","      (v_posed, torch.ones((batch_num, v_posed.shape[1], 1), dtype=torch.float64).to(self.device)), dim=2\n","    )\n","    v = torch.matmul(T, torch.reshape(rest_shape_h, (batch_num, -1, 4, 1)))\n","    v = torch.reshape(v, (batch_num, -1, 4))[:, :, :3]\n","    result = v + torch.reshape(trans, (batch_num, 1, 3))\n","    # estimate 3D joint locations\n","    # print(result.shape)\n","    # print(self.joint_regressor.shape)\n","    # joints = torch.tensordot(result, self.joint_regressor, dims=([1], [0])).transpose(1, 2)\n","        \n","    # pose_beta_seq = torch.cat((pose, betas),1)\n","    # dbs = self.dbs_layer(pose_beta_seq)\n","    # result += dbs\n","    \n","    return result\n","\n","\n","def test_gpu(dbs_type):\n","  # if len(gpu_id) > 0 and torch.cuda.is_available():\n","  #   os.environ['CUDA_VISIBLE_DEVICES'] = str(gpu_id[0])\n","  #   device = torch.device('cuda')\n","  # else:\n","  #   device = torch.device('cpu')\n","  #print(device)\n","  \n","  device = torch.device('cuda')\n","  print(torch.cuda.get_device_name(0))\n","  num_frames = 1000\n","  \n","  pose_size = 72\n","  beta_size = 10\n","\n","  np.random.seed(9608)\n","  model = DBSModel(device=device, model_path='/content/drive/My Drive/model.pkl', dbs_type=dbs_type,\\\n","                   num_c=[256,64,16],hd=1024)\n","  time_list = []\n","  for i in range(10):\n","      pose = torch.from_numpy((np.random.rand(num_frames, pose_size) - 0.5) * 0.4)\\\n","              .type(torch.float64).to(device)\n","      betas = torch.from_numpy((np.random.rand(num_frames, beta_size) - 0.5) * 0.06) \\\n","              .type(torch.float64).to(device)\n","      trans = torch.from_numpy(np.zeros((num_frames, 3))).type(torch.float64).to(device)\n","      \n","      s = time()\n","      result = model(betas, pose, trans)\n","      cost_time = time() - s\n","      print(cost_time)\n","      time_list.append(cost_time)\n","  print('mean cost:', np.mean(time_list[1:]))\n","      \n","   # outmesh_path = './dmpl_batch_obj/dmpl_torch_{}.obj'\n","   # for i in range(result.shape[0]):\n","   #      model.write_obj(result[i], outmesh_path.format(i))\n","\n","if __name__ == '__main__':\n","  test_gpu(dbs_type='tcn')"],"execution_count":24,"outputs":[{"output_type":"stream","text":["Tesla K80\n","0.0895700454711914\n","0.07889485359191895\n","0.07511186599731445\n","0.0733346939086914\n","0.07562041282653809\n","0.07160472869873047\n","0.07255005836486816\n","0.07156634330749512\n","0.07183670997619629\n","0.07600593566894531\n","mean cost: 0.07405840026007758\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"m0SHecqQe2B_","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":227},"executionInfo":{"status":"ok","timestamp":1597819933388,"user_tz":-480,"elapsed":3379,"user":{"displayName":"Haoran Chen","photoUrl":"","userId":"05150236894872546263"}},"outputId":"07d3a971-1f4f-42c0-d223-1fa1aaf57c6f"},"source":["class SMPLModel(Module):\n","  def __init__(self, device=None, model_path='./body_models/smpl/male/model.pkl'):\n","    \n","    super(SMPLModel, self).__init__()\n","    with open(model_path, 'rb') as f:\n","      params = pickle.load(f)\n","    self.J_regressor = torch.from_numpy(\n","      np.array(params['J_regressor'].todense())\n","    ).type(torch.float64)\n","    if 'joint_regressor' in params.keys():\n","      self.joint_regressor = torch.from_numpy(\n","        np.array(params['joint_regressor'].T.todense())\n","      ).type(torch.float64)\n","    else:\n","      self.joint_regressor = torch.from_numpy(\n","        np.array(params['J_regressor'].todense())\n","      ).type(torch.float64)\n","    self.weights = torch.from_numpy(params['weights']).type(torch.float64)\n","    self.posedirs = torch.from_numpy(params['posedirs']).type(torch.float64)\n","    self.v_template = torch.from_numpy(params['v_template']).type(torch.float64)\n","    self.shapedirs = torch.from_numpy(params['shapedirs']).type(torch.float64)\n","    self.kintree_table = params['kintree_table']\n","    self.faces = params['f']\n","    self.device = device if device is not None else torch.device('cpu')\n","    for name in ['J_regressor', 'joint_regressor', 'weights', 'posedirs', 'v_template', 'shapedirs']:\n","      _tensor = getattr(self, name)\n","      # print(' Tensor {} shape: '.format(name), _tensor.shape)\n","      setattr(self, name, _tensor.to(device))\n","\n","  @staticmethod\n","  def rodrigues(r):\n","    \"\"\"\n","    Rodrigues' rotation formula that turns axis-angle tensor into rotation\n","    matrix in a batch-ed manner.\n","\n","    Parameter:\n","    ----------\n","    r: Axis-angle rotation tensor of shape [batch_size * angle_num, 1, 3].\n","\n","    Return:\n","    -------\n","    Rotation matrix of shape [batch_size * angle_num, 3, 3].\n","\n","    \"\"\"\n","    eps = r.clone().normal_(std=1e-8)\n","    theta = torch.norm(r + eps, dim=(1, 2), keepdim=True)  # dim cannot be tuple\n","    theta_dim = theta.shape[0]\n","    r_hat = r / theta\n","    cos = torch.cos(theta)\n","    z_stick = torch.zeros(theta_dim, dtype=torch.float64).to(r.device)\n","    m = torch.stack(\n","      (z_stick, -r_hat[:, 0, 2], r_hat[:, 0, 1], r_hat[:, 0, 2], z_stick,\n","       -r_hat[:, 0, 0], -r_hat[:, 0, 1], r_hat[:, 0, 0], z_stick), dim=1)\n","    m = torch.reshape(m, (-1, 3, 3))\n","    i_cube = (torch.eye(3, dtype=torch.float64).unsqueeze(dim=0) \\\n","             + torch.zeros((theta_dim, 3, 3), dtype=torch.float64)).to(r.device)\n","    A = r_hat.permute(0, 2, 1)\n","    dot = torch.matmul(A, r_hat)\n","    R = cos * i_cube + (1 - cos) * dot + torch.sin(theta) * m\n","    return R\n","\n","  @staticmethod\n","  def with_zeros(x):\n","    \"\"\"\n","    Append a [0, 0, 0, 1] tensor to a [3, 4] tensor.\n","\n","    Parameter:\n","    ---------\n","    x: Tensor to be appended.\n","\n","    Return:\n","    ------\n","    Tensor after appending of shape [4,4]\n","\n","    \"\"\"\n","    ones = torch.tensor(\n","      [[[0.0, 0.0, 0.0, 1.0]]], dtype=torch.float64\n","    ).expand(x.shape[0],-1,-1).to(x.device)\n","    ret = torch.cat((x, ones), dim=1)\n","    return ret\n","\n","  @staticmethod\n","  def pack(x):\n","    \"\"\"\n","    Append zero tensors of shape [4, 3] to a batch of [4, 1] shape tensor.\n","\n","    Parameter:\n","    ----------\n","    x: A tensor of shape [batch_size, 4, 1]\n","\n","    Return:\n","    ------\n","    A tensor of shape [batch_size, 4, 4] after appending.\n","\n","    \"\"\"\n","    zeros43 = torch.zeros(\n","      (x.shape[0], x.shape[1], 4, 3), dtype=torch.float64).to(x.device)\n","    ret = torch.cat((zeros43, x), dim=3)\n","    return ret\n","\n","  def write_obj(self, verts, file_name):\n","    with open(file_name, 'w') as fp:\n","      for v in verts:\n","        fp.write('v %f %f %f\\n' % (v[0], v[1], v[2]))\n","\n","      for f in self.faces + 1:\n","        fp.write('f %d %d %d\\n' % (f[0], f[1], f[2]))\n","\n","  def forward(self, betas, pose, trans, simplify=False):\n","    \n","    \"\"\"\n","          Construct a compute graph that takes in parameters and outputs a tensor as\n","          model vertices. Face indices are also returned as a numpy ndarray.\n","          \n","          20190128: Add batch support.\n","\n","          Parameters:\n","          ---------\n","          pose: Also known as 'theta', an [N, 24, 3] tensor indicating child joint rotation\n","          relative to parent joint. For root joint it's global orientation.\n","          Represented in a axis-angle format.\n","\n","          betas: Parameter for model shape. A tensor of shape [N, 10] as coefficients of\n","          PCA components. Only 10 components were released by SMPL author.\n","\n","          trans: Global translation tensor of shape [N, 3].\n","\n","          Return:\n","          ------\n","          A 3-D tensor of [N * 6890 * 3] for vertices,\n","          and the corresponding [N * 19 * 3] joint positions.\n","\n","    \"\"\"\n","    batch_num = betas.shape[0]\n","    id_to_col = {self.kintree_table[1, i]: i\n","                 for i in range(self.kintree_table.shape[1])}\n","    parent = {\n","      i: id_to_col[self.kintree_table[0, i]]\n","      for i in range(1, self.kintree_table.shape[1])\n","    }\n","    v_shaped = torch.tensordot(betas, self.shapedirs, dims=([1], [2])) + self.v_template\n","    J = torch.matmul(self.J_regressor, v_shaped)\n","    R_cube_big = self.rodrigues(pose.view(-1, 1, 3)).reshape(batch_num, -1, 3, 3)\n","\n","    if simplify:\n","      v_posed = v_shaped\n","    else:\n","      R_cube = R_cube_big[:, 1:, :, :]\n","      I_cube = (torch.eye(3, dtype=torch.float64).unsqueeze(dim=0) + \\\n","        torch.zeros((batch_num, R_cube.shape[1], 3, 3), dtype=torch.float64)).to(self.device)\n","      lrotmin = (R_cube - I_cube).reshape(batch_num, -1, 1).squeeze(dim=2)\n","      v_posed = v_shaped + torch.tensordot(lrotmin, self.posedirs, dims=([1], [2]))\n","\n","    results = []\n","    results.append(\n","      self.with_zeros(torch.cat((R_cube_big[:, 0], torch.reshape(J[:, 0, :], (-1, 3, 1))), dim=2))\n","    )\n","    for i in range(1, self.kintree_table.shape[1]):\n","      results.append(\n","        torch.matmul(\n","          results[parent[i]],\n","          self.with_zeros(\n","            torch.cat(\n","              (R_cube_big[:, i], torch.reshape(J[:, i, :] - J[:, parent[i], :], (-1, 3, 1))),\n","              dim=2\n","            )\n","          )\n","        )\n","      )\n","    \n","    stacked = torch.stack(results, dim=1)\n","    results = stacked - \\\n","      self.pack(\n","        torch.matmul(\n","          stacked,\n","          torch.reshape(\n","            torch.cat((J, torch.zeros((batch_num, 24, 1), dtype=torch.float64).to(self.device)), dim=2),\n","            (batch_num, 24, 4, 1)\n","          )\n","        )\n","      )\n","    # Restart from here\n","    T = torch.tensordot(results, self.weights, dims=([1], [1])).permute(0, 3, 1, 2)\n","    rest_shape_h = torch.cat(\n","      (v_posed, torch.ones((batch_num, v_posed.shape[1], 1), dtype=torch.float64).to(self.device)), dim=2\n","    )\n","    v = torch.matmul(T, torch.reshape(rest_shape_h, (batch_num, -1, 4, 1)))\n","    v = torch.reshape(v, (batch_num, -1, 4))[:, :, :3]\n","    result = v + torch.reshape(trans, (batch_num, 1, 3))\n","    # estimate 3D joint locations\n","    # print(result.shape)\n","    # print(self.joint_regressor.shape)\n","    # joints = torch.tensordot(result, self.joint_regressor, dims=([1], [0])).transpose(1, 2)\n","    return result\n","\n","def test_gpu():\n","  # if len(gpu_id) > 0 and torch.cuda.is_available():\n","  #   os.environ['CUDA_VISIBLE_DEVICES'] = str(gpu_id[0])\n","  #   device = torch.device('cuda')\n","  # else:\n","  #   device = torch.device('cpu')\n","  #print(device)\n","  \n","  device = torch.device('cuda')\n","  print(torch.cuda.get_device_name(0))\n","  num_frames = 1000\n","  \n","  pose_size = 72\n","  beta_size = 10\n","\n","  np.random.seed(9608)\n","  model = SMPLModel(device=device, model_path='/content/drive/My Drive/model.pkl')\n","  time_list = []\n","  for i in range(10):\n","      pose = torch.from_numpy((np.random.rand(num_frames, pose_size) - 0.5) * 0.4)\\\n","              .type(torch.float64).to(device)\n","      betas = torch.from_numpy((np.random.rand(num_frames, beta_size) - 0.5) * 0.06) \\\n","              .type(torch.float64).to(device)\n","      trans = torch.from_numpy(np.zeros((num_frames, 3))).type(torch.float64).to(device)\n","      \n","      s = time()\n","      result = model(betas, pose, trans)\n","      cost_time = time() - s\n","      print(cost_time)\n","      time_list.append(cost_time)\n","  print('mean cost:', np.mean(time_list[1:]))\n","      \n","   # outmesh_path = './dmpl_batch_obj/dmpl_torch_{}.obj'\n","   # for i in range(result.shape[0]):\n","   #      model.write_obj(result[i], outmesh_path.format(i))\n","\n","if __name__ == '__main__':\n","  test_gpu()"],"execution_count":26,"outputs":[{"output_type":"stream","text":["Tesla K80\n","0.07825493812561035\n","0.07197904586791992\n","0.0688169002532959\n","0.06967878341674805\n","0.0648200511932373\n","0.06434917449951172\n","0.06195974349975586\n","0.06177520751953125\n","0.06447529792785645\n","0.0614781379699707\n","mean cost: 0.06548137134975857\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"jAkMImNHfkS7","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":227},"executionInfo":{"status":"ok","timestamp":1597820499171,"user_tz":-480,"elapsed":3637,"user":{"displayName":"Haoran Chen","photoUrl":"","userId":"05150236894872546263"}},"outputId":"67a05ec2-7c4c-4522-fad4-93f13d4e25c8"},"source":["class DMPLModel(Module):\n","  def __init__(self, device=None, model_path='./body_models/smpl/male/model.pkl'):\n","    \n","    super(DMPLModel, self).__init__()\n","    with open(model_path, 'rb') as f:\n","      params = pickle.load(f)\n","    self.J_regressor = torch.from_numpy(\n","      np.array(params['J_regressor'].todense())\n","    ).type(torch.float64)\n","    if 'joint_regressor' in params.keys():\n","      self.joint_regressor = torch.from_numpy(\n","        np.array(params['joint_regressor'].T.todense())\n","      ).type(torch.float64)\n","    else:\n","      self.joint_regressor = torch.from_numpy(\n","        np.array(params['J_regressor'].todense())\n","      ).type(torch.float64)\n","    self.weights = torch.from_numpy(params['weights']).type(torch.float64)\n","    self.posedirs = torch.from_numpy(params['posedirs']).type(torch.float64)\n","    self.v_template = torch.from_numpy(params['v_template']).type(torch.float64)\n","    self.shapedirs = torch.from_numpy(params['shapedirs']).type(torch.float64)\n","    self.kintree_table = params['kintree_table']\n","    self.faces = params['f']\n","    self.device = device if device is not None else torch.device('cpu')\n","    for name in ['J_regressor', 'joint_regressor', 'weights', 'posedirs', 'v_template', 'shapedirs']:\n","      _tensor = getattr(self, name)\n","      # print(' Tensor {} shape: '.format(name), _tensor.shape)\n","      setattr(self, name, _tensor.to(device))\n","    DMPL_params = np.load(\"/content/drive/My Drive/model.npz\")\n","    self.dmpls_eig = torch.Tensor(DMPL_params['eigvec']).type(torch.float64).to(device)\n","    # self.dmpls_eig *= 2\n","\n","  @staticmethod\n","  def rodrigues(r):\n","    \"\"\"\n","    Rodrigues' rotation formula that turns axis-angle tensor into rotation\n","    matrix in a batch-ed manner.\n","\n","    Parameter:\n","    ----------\n","    r: Axis-angle rotation tensor of shape [batch_size * angle_num, 1, 3].\n","\n","    Return:\n","    -------\n","    Rotation matrix of shape [batch_size * angle_num, 3, 3].\n","\n","    \"\"\"\n","    eps = r.clone().normal_(std=1e-8)\n","    theta = torch.norm(r + eps, dim=(1, 2), keepdim=True)  # dim cannot be tuple\n","    theta_dim = theta.shape[0]\n","    r_hat = r / theta\n","    cos = torch.cos(theta)\n","    z_stick = torch.zeros(theta_dim, dtype=torch.float64).to(r.device)\n","    m = torch.stack(\n","      (z_stick, -r_hat[:, 0, 2], r_hat[:, 0, 1], r_hat[:, 0, 2], z_stick,\n","       -r_hat[:, 0, 0], -r_hat[:, 0, 1], r_hat[:, 0, 0], z_stick), dim=1)\n","    m = torch.reshape(m, (-1, 3, 3))\n","    i_cube = (torch.eye(3, dtype=torch.float64).unsqueeze(dim=0) \\\n","             + torch.zeros((theta_dim, 3, 3), dtype=torch.float64)).to(r.device)\n","    A = r_hat.permute(0, 2, 1)\n","    dot = torch.matmul(A, r_hat)\n","    R = cos * i_cube + (1 - cos) * dot + torch.sin(theta) * m\n","    return R\n","\n","  @staticmethod\n","  def with_zeros(x):\n","    \"\"\"\n","    Append a [0, 0, 0, 1] tensor to a [3, 4] tensor.\n","\n","    Parameter:\n","    ---------\n","    x: Tensor to be appended.\n","\n","    Return:\n","    ------\n","    Tensor after appending of shape [4,4]\n","\n","    \"\"\"\n","    ones = torch.tensor(\n","      [[[0.0, 0.0, 0.0, 1.0]]], dtype=torch.float64\n","    ).expand(x.shape[0],-1,-1).to(x.device)\n","    ret = torch.cat((x, ones), dim=1)\n","    return ret\n","\n","  @staticmethod\n","  def pack(x):\n","    \"\"\"\n","    Append zero tensors of shape [4, 3] to a batch of [4, 1] shape tensor.\n","\n","    Parameter:\n","    ----------\n","    x: A tensor of shape [batch_size, 4, 1]\n","\n","    Return:\n","    ------\n","    A tensor of shape [batch_size, 4, 4] after appending.\n","\n","    \"\"\"\n","    zeros43 = torch.zeros(\n","      (x.shape[0], x.shape[1], 4, 3), dtype=torch.float64).to(x.device)\n","    ret = torch.cat((zeros43, x), dim=3)\n","    return ret\n","\n","  def write_obj(self, verts, file_name):\n","    with open(file_name, 'w') as fp:\n","      for v in verts:\n","        fp.write('v %f %f %f\\n' % (v[0], v[1], v[2]))\n","\n","      for f in self.faces + 1:\n","        fp.write('f %d %d %d\\n' % (f[0], f[1], f[2]))\n","\n","  def forward(self, betas, pose, trans, dmpls, simplify=False):\n","    \n","    \"\"\"\n","          Construct a compute graph that takes in parameters and outputs a tensor as\n","          model vertices. Face indices are also returned as a numpy ndarray.\n","          \n","          20190128: Add batch support.\n","\n","          Parameters:\n","          ---------\n","          pose: Also known as 'theta', an [N, 24, 3] tensor indicating child joint rotation\n","          relative to parent joint. For root joint it's global orientation.\n","          Represented in a axis-angle format.\n","\n","          betas: Parameter for model shape. A tensor of shape [N, 10] as coefficients of\n","          PCA components. Only 10 components were released by SMPL author.\n","\n","          trans: Global translation tensor of shape [N, 3].\n","\n","          Return:\n","          ------\n","          A 3-D tensor of [N * 6890 * 3] for vertices,\n","          and the corresponding [N * 19 * 3] joint positions.\n","\n","    \"\"\"\n","    batch_num = betas.shape[0]\n","    id_to_col = {self.kintree_table[1, i]: i\n","                 for i in range(self.kintree_table.shape[1])}\n","    parent = {\n","      i: id_to_col[self.kintree_table[0, i]]\n","      for i in range(1, self.kintree_table.shape[1])\n","    }\n","    v_shaped = torch.tensordot(betas, self.shapedirs, dims=([1], [2])) + self.v_template\n","    J = torch.matmul(self.J_regressor, v_shaped)\n","    R_cube_big = self.rodrigues(pose.view(-1, 1, 3)).reshape(batch_num, -1, 3, 3)\n","\n","    if simplify:\n","      v_posed = v_shaped\n","    else:\n","      R_cube = R_cube_big[:, 1:, :, :]\n","      I_cube = (torch.eye(3, dtype=torch.float64).unsqueeze(dim=0) + \\\n","        torch.zeros((batch_num, R_cube.shape[1], 3, 3), dtype=torch.float64)).to(self.device)\n","      lrotmin = (R_cube - I_cube).reshape(batch_num, -1, 1).squeeze(dim=2)\n","      v_posed = v_shaped + torch.tensordot(lrotmin, self.posedirs, dims=([1], [2]))\n","    \n","    dbs = torch.tensordot(self.dmpls_eig, dmpls, dims=([2],[1]))\n","    dbs = dbs.permute(2,0,1)\n","    v_posed += dbs\n","    \n","    results = []\n","    results.append(\n","      self.with_zeros(torch.cat((R_cube_big[:, 0], torch.reshape(J[:, 0, :], (-1, 3, 1))), dim=2))\n","    )\n","    for i in range(1, self.kintree_table.shape[1]):\n","      results.append(\n","        torch.matmul(\n","          results[parent[i]],\n","          self.with_zeros(\n","            torch.cat(\n","              (R_cube_big[:, i], torch.reshape(J[:, i, :] - J[:, parent[i], :], (-1, 3, 1))),\n","              dim=2\n","            )\n","          )\n","        )\n","      )\n","    \n","    stacked = torch.stack(results, dim=1)\n","    results = stacked - \\\n","      self.pack(\n","        torch.matmul(\n","          stacked,\n","          torch.reshape(\n","            torch.cat((J, torch.zeros((batch_num, 24, 1), dtype=torch.float64).to(self.device)), dim=2),\n","            (batch_num, 24, 4, 1)\n","          )\n","        )\n","      )\n","    # Restart from here\n","    T = torch.tensordot(results, self.weights, dims=([1], [1])).permute(0, 3, 1, 2)\n","    rest_shape_h = torch.cat(\n","      (v_posed, torch.ones((batch_num, v_posed.shape[1], 1), dtype=torch.float64).to(self.device)), dim=2\n","    )\n","    v = torch.matmul(T, torch.reshape(rest_shape_h, (batch_num, -1, 4, 1)))\n","    v = torch.reshape(v, (batch_num, -1, 4))[:, :, :3]\n","    result = v + torch.reshape(trans, (batch_num, 1, 3))\n","    # estimate 3D joint locations\n","    # print(result.shape)\n","    # print(self.joint_regressor.shape)\n","    # joints = torch.tensordot(result, self.joint_regressor, dims=([1], [0])).transpose(1, 2)\n","    \n","    # dbs = torch.tensordot(self.dmpls_eig, dmpls, dims=([2],[1]))\n","    # dbs = dbs.permute(2,0,1)\n","    # result += dbs\n","    return result\n","\n","def test_gpu():\n","  # if len(gpu_id) > 0 and torch.cuda.is_available():\n","  #   os.environ['CUDA_VISIBLE_DEVICES'] = str(gpu_id[0])\n","  #   device = torch.device('cuda')\n","  # else:\n","  #   device = torch.device('cpu')\n","  #print(device)\n","  \n","  device = torch.device('cuda')\n","  print(torch.cuda.get_device_name(0))\n","  num_frames = 1000\n","  \n","  pose_size = 72\n","  beta_size = 10\n","  dmpls_size = 8\n","\n","  np.random.seed(9608)\n","  model = DMPLModel(device=device, model_path='/content/drive/My Drive/model.pkl')\n","  time_list = []\n","  for i in range(10):\n","      pose = torch.from_numpy((np.random.rand(num_frames, pose_size) - 0.5) * 0.4)\\\n","              .type(torch.float64).to(device)\n","      betas = torch.from_numpy((np.random.rand(num_frames, beta_size) - 0.5) * 0.06) \\\n","              .type(torch.float64).to(device)\n","      trans = torch.from_numpy(np.zeros((num_frames, 3))).type(torch.float64).to(device)\n","      dmpls = torch.from_numpy((np.random.rand(num_frames, dmpls_size))).type(torch.float64).to(device)\n","\n","      s = time()\n","      result = model(betas, pose, trans, dmpls)\n","      cost_time = time() - s\n","      print(cost_time)\n","      time_list.append(cost_time)\n","  print('mean cost:', np.mean(time_list[1:]))\n","      \n","   # outmesh_path = './dmpl_batch_obj/dmpl_torch_{}.obj'\n","   # for i in range(result.shape[0]):\n","   #      model.write_obj(result[i], outmesh_path.format(i))\n","\n","if __name__ == '__main__':\n","  test_gpu()"],"execution_count":30,"outputs":[{"output_type":"stream","text":["Tesla K80\n","0.09332990646362305\n","0.08585476875305176\n","0.08218264579772949\n","0.07542800903320312\n","0.07521462440490723\n","0.07555079460144043\n","0.07386207580566406\n","0.07398128509521484\n","0.07248687744140625\n","0.074127197265625\n","mean cost: 0.07652091979980469\n"],"name":"stdout"}]}]}